{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# BLUEPRINT: BUILDING YOUR OWN VECTORISER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['worst', 0],\n",
       " ['wisdom', 1],\n",
       " ['age', 2],\n",
       " ['the', 3],\n",
       " ['of', 4],\n",
       " ['times', 5],\n",
       " ['best', 6],\n",
       " ['It', 7],\n",
       " ['was', 8],\n",
       " ['foolishness', 9]]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Enumerate vocabulary\n",
    "# Interested in whether a word appears in a document or not, we just enumerate the words\n",
    "sentences = [\"It was the best of times\",\n",
    "            \"It was the worst of times\",\n",
    "            \"It was the age of wisdom\",\n",
    "            \"It was the age of foolishness\"]\n",
    "tokenised_sentences = [[token for token in sentence.split()] for sentence in sentences]\n",
    "vocabulary = set([w for s in tokenised_sentences for w in s])\n",
    "[[w,i] for i,w in enumerate(vocabulary)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 0, 0, 1, 1, 1, 1, 1, 1, 0]: It was the best of times\n",
      "[1, 0, 0, 1, 1, 1, 0, 1, 1, 0]: It was the worst of times\n",
      "[0, 1, 1, 1, 1, 0, 0, 1, 1, 0]: It was the age of wisdom\n",
      "[0, 0, 1, 1, 1, 0, 0, 1, 1, 1]: It was the age of foolishness\n",
      "First 10 records of onehot_df:\n",
      "   worst  wisdom  age  the  of  times  best  It  was  foolishness\n",
      "0      0       0    0    1   1      1     1   1    1            0\n",
      "1      1       0    0    1   1      1     0   1    1            0\n",
      "2      0       1    1    1   1      0     0   1    1            0\n",
      "3      0       0    1    1   1      0     0   1    1            1\n",
      "[0, 0, 0, 1, 1, 1, 0, 1, 1, 0]\n",
      "Sum of sim: 5\n",
      "5\n",
      "[5 6 4 4]\n"
     ]
    }
   ],
   "source": [
    "# One-hot encoding\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "def onehot_encode(tokenised_sentence, vocabulary):\n",
    "    return [1 if w in tokenised_sentence else 0 for w in vocabulary]\n",
    "onehot = [onehot_encode(tokenised_sentence, vocabulary) for tokenised_sentence in tokenised_sentences]\n",
    "for (sentence, oh) in zip(sentences, onehot):\n",
    "    print(f\"{oh}: {sentence}\")\n",
    "onehot_df = pd.DataFrame(onehot, columns = vocabulary)\n",
    "print(f\"First 10 records of onehot_df:\\n{onehot_df.head(10)}\")\n",
    "# Determine similarity between first 2 tokenised sentences\n",
    "sim = [onehot[0][i] & onehot[1][i] for i in range(0, len(vocabulary))] # & performs bit-wise operation\n",
    "print(sim)\n",
    "print(f\"Sum of sim: {sum(sim)}\")\n",
    "import numpy as np\n",
    "print(np.dot(onehot[0], onehot[1]))\n",
    "# Determine similarity between all tokenised sentences with second tokenised_sentence\n",
    "print(np.dot(onehot, onehot[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 1, 1, 1, 1, 1, 1, 0, 0, 0]\n",
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n"
     ]
    }
   ],
   "source": [
    "# Out of vocabulary\n",
    "print(onehot_encode(\"the age of wisdom is the best of times\".split(), vocabulary))\n",
    "print(onehot_encode(\"John likes to watch movies. Mary likes to watch movies too\".split(), vocabulary))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0, 0, 0, 1, 1, 1, 1, 1, 1, 0], [1, 0, 0, 1, 1, 1, 0, 1, 1, 0], [0, 1, 1, 1, 1, 0, 0, 1, 1, 0], [0, 0, 1, 1, 1, 0, 0, 1, 1, 1]]\n"
     ]
    }
   ],
   "source": [
    "# Document term matrix\n",
    "print(onehot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[6 5 4 4]\n",
      " [5 6 4 4]\n",
      " [4 4 6 5]\n",
      " [4 4 5 6]]\n"
     ]
    }
   ],
   "source": [
    "# Similarities\n",
    "sim_df = np.dot(onehot, np.transpose(onehot))\n",
    "print(sim_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['It' 'age' 'best' 'foolishness' 'of' 'the' 'times' 'was' 'wisdom' 'worst']\n",
      "{'worst', 'wisdom', 'age', 'the', 'of', 'times', 'best', 'It', 'was', 'foolishness'}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[1, 0, 1, 0, 1, 1, 1, 1, 0, 0],\n",
       "       [1, 0, 0, 0, 1, 1, 1, 1, 0, 1],\n",
       "       [1, 1, 0, 0, 1, 1, 0, 1, 1, 0],\n",
       "       [1, 1, 0, 1, 1, 1, 0, 1, 0, 0]])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Scikit-learn one-hot vectorisation\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "lb = MultiLabelBinarizer()\n",
    "lb.fit([vocabulary])\n",
    "# Show classes\n",
    "print(lb.classes_)\n",
    "print(vocabulary) # Arrangement of tokens different between lb.classes_ and vpcabulary\n",
    "lb.transform(tokenised_sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First 5 records of df:\n",
      "                                                   0\n",
      "0                           It was the best of times\n",
      "1                          It was the worst of times\n",
      "2                           It was the age of wisdom\n",
      "3                      It was the age of foolishness\n",
      "4  John likes to watch movies. Mary likes movies ...\n",
      "['age', 'also', 'best', 'foolishness', 'football', 'games', 'it', 'john', 'likes', 'mary', 'movies', 'of', 'the', 'times', 'to', 'too', 'was', 'watch', 'wisdom', 'worst']\n",
      "  (0, 2)\t1\n",
      "  (0, 6)\t1\n",
      "  (0, 11)\t1\n",
      "  (0, 12)\t1\n",
      "  (0, 13)\t1\n",
      "  (0, 16)\t1\n",
      "  (1, 6)\t1\n",
      "  (1, 11)\t1\n",
      "  (1, 12)\t1\n",
      "  (1, 13)\t1\n",
      "  (1, 16)\t1\n",
      "  (1, 19)\t1\n",
      "  (2, 0)\t1\n",
      "  (2, 6)\t1\n",
      "  (2, 11)\t1\n",
      "  (2, 12)\t1\n",
      "  (2, 16)\t1\n",
      "  (2, 18)\t1\n",
      "  (3, 0)\t1\n",
      "  (3, 3)\t1\n",
      "  (3, 6)\t1\n",
      "  (3, 11)\t1\n",
      "  (3, 12)\t1\n",
      "  (3, 16)\t1\n",
      "  (4, 7)\t1\n",
      "  (4, 8)\t2\n",
      "  (4, 9)\t1\n",
      "  (4, 10)\t2\n",
      "  (4, 14)\t1\n",
      "  (4, 15)\t1\n",
      "  (4, 17)\t1\n",
      "  (5, 1)\t1\n",
      "  (5, 4)\t1\n",
      "  (5, 5)\t1\n",
      "  (5, 8)\t1\n",
      "  (5, 9)\t1\n",
      "  (5, 14)\t1\n",
      "  (5, 17)\t1\n",
      "dt_df:\n",
      "   age  also  best  foolishness  football  games  it  john  likes  mary  \\\n",
      "0    0     0     1            0         0      0   1     0      0     0   \n",
      "1    0     0     0            0         0      0   1     0      0     0   \n",
      "2    1     0     0            0         0      0   1     0      0     0   \n",
      "3    1     0     0            1         0      0   1     0      0     0   \n",
      "4    0     0     0            0         0      0   0     1      2     1   \n",
      "5    0     1     0            0         1      1   0     0      1     1   \n",
      "\n",
      "   movies  of  the  times  to  too  was  watch  wisdom  worst  \n",
      "0       0   1    1      1   0    0    1      0       0      0  \n",
      "1       0   1    1      1   0    0    1      0       0      1  \n",
      "2       0   1    1      0   0    0    1      0       1      0  \n",
      "3       0   1    1      0   0    0    1      0       0      0  \n",
      "4       2   0    0      0   1    1    0      1       0      0  \n",
      "5       0   0    0      0   1    0    0      1       0      0  \n",
      "similarity_df:\n",
      "          0         1         2         3         4         5\n",
      "0  1.000000  0.833333  0.666667  0.666667  0.000000  0.000000\n",
      "1  0.833333  1.000000  0.666667  0.666667  0.000000  0.000000\n",
      "2  0.666667  0.666667  1.000000  0.833333  0.000000  0.000000\n",
      "3  0.666667  0.666667  0.833333  1.000000  0.000000  0.000000\n",
      "4  0.000000  0.000000  0.000000  0.000000  1.000000  0.524142\n",
      "5  0.000000  0.000000  0.000000  0.000000  0.524142  1.000000\n"
     ]
    }
   ],
   "source": [
    "# CountVectorizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "cv = CountVectorizer()\n",
    "# Add more sentences\n",
    "more_sentences = sentences + [\"John likes to watch movies. Mary likes movies too.\",\n",
    "                              \"Mary also likes to watch football games.\"]\n",
    "# Convert to Pandas dataframe\n",
    "more_sentences_df = pd.DataFrame(more_sentences)\n",
    "print(f\"First 5 records of df:\\n{more_sentences_df.head(5)}\")\n",
    "# Fit\n",
    "cv.fit(more_sentences)\n",
    "# Show features\n",
    "print(cv.get_feature_names())\n",
    "# Transform\n",
    "dt = cv.transform(more_sentences)\n",
    "print(dt)\n",
    "# Convert to Pandas dataframe\n",
    "dt_df = pd.DataFrame(dt.toarray(), columns = cv.get_feature_names())\n",
    "# Show dt_df\n",
    "print(f\"dt_df:\\n{dt_df}\")\n",
    "# Get similarity matrix\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "# Similarity between first and second documents\n",
    "cosine_similarity(dt[0], dt[1])\n",
    "# Store similarity matrix as Pandas dataframe\n",
    "similarity_df = pd.DataFrame(cosine_similarity(dt, dt))\n",
    "# Show similarity\n",
    "print(f\"similarity_df:\\n{similarity_df}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
